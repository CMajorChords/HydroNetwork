{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Zonal Exchange Network\n",
    "ZEN（Zonal Exchange Network） 是一个原创的水文模型，用于模拟流域内的水文过程。ZEN使用神经网络来描述产汇流过程。"
   ],
   "id": "5f4008014cc71dce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T15:09:51.954844Z",
     "start_time": "2024-11-07T15:09:51.656355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 自动加载模块\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# 清除所有变量\n",
    "from hydronetwork.utils import clear_all\n",
    "\n",
    "clear_all()"
   ],
   "id": "d34fbc19312b9e35",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'clear_all' from 'hydronetwork.utils' (C:\\Users\\18313\\PycharmProjects\\HydroNetwork\\hydronetwork\\utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_line_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mautoreload\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# 清除所有变量\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhydronetwork\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m clear_all\n\u001B[0;32m      7\u001B[0m clear_all()\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'clear_all' from 'hydronetwork.utils' (C:\\Users\\18313\\PycharmProjects\\HydroNetwork\\hydronetwork\\utils.py)"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. 数据处理",
   "id": "fb837cc32bc89b3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T15:09:52.029887900Z",
     "start_time": "2024-11-05T12:18:44.528193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from hydronetwork.data.camels_us import load_timeseries\n",
    "from hydronetwork.dataset.preprocessing import split_timeseries\n",
    "from hydronetwork.dataset.dataset import get_dataset\n",
    "\n",
    "lookback = 365\n",
    "horizon = 7\n",
    "timeseries = load_timeseries(gauge_id='13023000', unit=\"mm/day\")\n",
    "timeseries.columns"
   ],
   "id": "8375ddf5a87d68cf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['prcp(mm/day)', 'srad(W/m2)', 'tmax(C)', 'tmin(C)', 'vp(Pa)',\n",
       "       'streamflow'],\n",
       "      dtype='object', name='timeseries_type')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "对['srad(W/m2)', 'tmax(C)', 'tmin(C)', 'vp(Pa)']进行归一化",
   "id": "a9fa419d215db6d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T15:09:52.029887900Z",
     "start_time": "2024-11-05T12:18:44.702689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from hydronetwork.dataset.preprocessing import normalize\n",
    "\n",
    "timeseries_need_normalize = timeseries[['srad(W/m2)', 'tmax(C)', 'tmin(C)', 'vp(Pa)']]\n",
    "timeseries_normalized = normalize(timeseries_need_normalize)\n",
    "timeseries = timeseries.drop(columns=['srad(W/m2)', 'tmax(C)', 'tmin(C)', 'vp(Pa)'])\n",
    "timeseries = timeseries.join(timeseries_normalized)"
   ],
   "id": "cefc0e3a4f5020b4",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "构建数据集",
   "id": "2445ed5c281b6a4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T15:09:52.029887900Z",
     "start_time": "2024-11-05T12:18:44.821642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train_data, test_data = split_timeseries(timeseries, split_list=[0.8, 0.2])\n",
    "# train_dataset = get_dataset(train_data, \n",
    "#                             lookback=lookback, \n",
    "#                             horizon=horizon, \n",
    "#                             batch_size=2048, \n",
    "#                             features_bidirectional=['prcp(mm/day)', 'srad(W/m2)', 'tmax(C)', 'tmin(C)', 'vp(Pa)'],\n",
    "#                             target=\"streamflow\"\n",
    "#                             )\n",
    "# test_dataset = get_dataset(test_data,\n",
    "#                             lookback=lookback,\n",
    "#                             horizon=horizon,\n",
    "#                             batch_size=2048,\n",
    "#                             features_bidirectional=['prcp(mm/day)', 'srad(W/m2)', 'tmax(C)', 'tmin(C)', 'vp(Pa)'],\n",
    "#                             target=\"streamflow\"\n",
    "#                             )\n",
    "dataset = get_dataset(timeseries,\n",
    "                      lookback=lookback,\n",
    "                      horizon=horizon,\n",
    "                      batch_size=1024,\n",
    "                      features_bidirectional=['prcp(mm/day)', 'srad(W/m2)', 'tmax(C)', 'tmin(C)', 'vp(Pa)'],\n",
    "                      target=\"streamflow\"\n",
    "                      )"
   ],
   "id": "c96cd9dcb0b4d11a",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. 模型构建",
   "id": "d4a7a6027ff66b4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T15:09:52.029887900Z",
     "start_time": "2024-11-05T12:18:44.953827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from hydronetwork.model import ZonalExchangeNet\n",
    "\n",
    "model = ZonalExchangeNet(m=3,\n",
    "                         n=128,\n",
    "                         n_mix_steps=3,\n",
    "                         water_capacity_max=120,\n",
    "                         layer_units=[32, 16, 1],\n",
    "                         horizon=horizon, )"
   ],
   "id": "f57a9be3fcd9b30f",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. 模型训练",
   "id": "6dc1c1ab11dfa940"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T15:09:52.029887900Z",
     "start_time": "2024-11-05T12:18:45.044773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from hydronetwork.train import WarmupExponentialDecay, callback_for_features_selection\n",
    "from hydronetwork.evaluate.metrics import rmse, nse\n",
    "from keras.src.optimizers import AdamW\n",
    "\n",
    "model.compile(optimizer=AdamW(learning_rate=WarmupExponentialDecay(dataset_length=len(dataset),\n",
    "                                                                   initial_learning_rate=1e-4, )),\n",
    "              loss=nse,\n",
    "              metrics=[rmse]\n",
    "              )\n",
    "model.fit(dataset,\n",
    "          epochs=500,\n",
    "          verbose=1,\n",
    "          shuffle=True,\n",
    "          callbacks=callback_for_features_selection())"
   ],
   "id": "bbd1bdf503a31aa3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001B[1m 5/13\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m42s\u001B[0m 5s/step - loss: 96.5390 - rmse: 8.2017 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 10\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptimizers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AdamW\n\u001B[0;32m      5\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39mAdamW(learning_rate\u001B[38;5;241m=\u001B[39mWarmupExponentialDecay(dataset_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(dataset),\n\u001B[0;32m      6\u001B[0m                                                                    initial_learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-4\u001B[39m, )),\n\u001B[0;32m      7\u001B[0m               loss\u001B[38;5;241m=\u001B[39mnse,\n\u001B[0;32m      8\u001B[0m               metrics\u001B[38;5;241m=\u001B[39m[rmse]\n\u001B[0;32m      9\u001B[0m               )\n\u001B[1;32m---> 10\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(dataset,\n\u001B[0;32m     11\u001B[0m           epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m500\u001B[39m,\n\u001B[0;32m     12\u001B[0m           verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m     13\u001B[0m           shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m     14\u001B[0m           callbacks\u001B[38;5;241m=\u001B[39mcallback_for_features_selection())\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Hydro\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Hydro\\Lib\\site-packages\\keras\\src\\backend\\torch\\trainer.py:256\u001B[0m, in \u001B[0;36mTorchTrainer.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, data \u001B[38;5;129;01min\u001B[39;00m epoch_iterator\u001B[38;5;241m.\u001B[39menumerate_epoch():\n\u001B[0;32m    253\u001B[0m     \u001B[38;5;66;03m# Callbacks\u001B[39;00m\n\u001B[0;32m    254\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m--> 256\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_function(data)\n\u001B[0;32m    258\u001B[0m     \u001B[38;5;66;03m# Callbacks\u001B[39;00m\n\u001B[0;32m    259\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_end(step, logs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Hydro\\Lib\\site-packages\\keras\\src\\backend\\torch\\trainer.py:117\u001B[0m, in \u001B[0;36mTorchTrainer.make_train_function.<locals>.one_step_on_data\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001B[39;00m\n\u001B[0;32m    116\u001B[0m data \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m--> 117\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_step(data)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Hydro\\Lib\\site-packages\\keras\\src\\backend\\torch\\trainer.py:65\u001B[0m, in \u001B[0;36mTorchTrainer.train_step\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;66;03m# Compute gradients\u001B[39;00m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainable_weights:\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;66;03m# Call torch.Tensor.backward() on the loss to compute gradients\u001B[39;00m\n\u001B[0;32m     64\u001B[0m     \u001B[38;5;66;03m# for the weights.\u001B[39;00m\n\u001B[1;32m---> 65\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     67\u001B[0m     trainable_weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainable_weights[:]\n\u001B[0;32m     68\u001B[0m     gradients \u001B[38;5;241m=\u001B[39m [v\u001B[38;5;241m.\u001B[39mvalue\u001B[38;5;241m.\u001B[39mgrad \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m trainable_weights]\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Hydro\\Lib\\site-packages\\torch\\_tensor.py:581\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    572\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    573\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    574\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    579\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    580\u001B[0m     )\n\u001B[1;32m--> 581\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[0;32m    582\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[0;32m    583\u001B[0m )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Hydro\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 347\u001B[0m _engine_run_backward(\n\u001B[0;32m    348\u001B[0m     tensors,\n\u001B[0;32m    349\u001B[0m     grad_tensors_,\n\u001B[0;32m    350\u001B[0m     retain_graph,\n\u001B[0;32m    351\u001B[0m     create_graph,\n\u001B[0;32m    352\u001B[0m     inputs,\n\u001B[0;32m    353\u001B[0m     allow_unreachable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    354\u001B[0m     accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    355\u001B[0m )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Hydro\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    823\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    824\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 825\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    826\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    827\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    828\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    829\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fa813d99de2ef145"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
